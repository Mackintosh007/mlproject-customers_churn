{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef6411c5-b394-4b57-a82b-7ecd26cc76a8",
   "metadata": {},
   "source": [
    "## CUSTOMERS CHURN PREDICTIVE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1666e1f9-40ea-487c-849c-37c3e337af13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the dependencies\n",
    "!pip install catboost\n",
    "!pip install xgboost\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# modeling\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score # For evaluation\n",
    "from sklearn.linear_model import LogisticRegression # For linear classification\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from catboost import CatBoostRegressor # parameters for classification\n",
    "from xgboost import XGBClassifier # Convenience class for XGBoost classification\n",
    "import warnings \n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b07fed39-81ea-4ed6-abc0-37ea25af4d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the dataset\n",
    "df = pd.read_csv('02 churn-dataset.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad58031f-9625-43c7-aefa-293c16e92b01",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b48292c9-771e-4a2a-b9df-ce7efa24e1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking for missing values\n",
    "missing_values = df.isnull().sum()\n",
    "missing_value_percentage = (missing_values/len(df)) * 100\n",
    "print(missing_values)\n",
    "print(missing_value_percentage)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb45356a-84c5-4a79-857d-01a89a6d5b22",
   "metadata": {},
   "source": [
    "### Splitting the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc586287-9f7e-49dd-82de-fce611a6a696",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.drop(columns=['Churn', 'customerID'], axis = 1) \n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794cfad0-b46c-4f0b-a5c7-218e5ad395b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ddc56f-74b8-4f11-b087-112c0f0683ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking all the categorical columns\n",
    "print(\"The categories in 'gender' variables;.......\", end=\" \")\n",
    "print(df['gender'].unique())\n",
    "\n",
    "print(\"The categories in 'SeniorCitizen' variables;.......\", end=\" \")\n",
    "print(df['SeniorCitizen'].unique())\n",
    "\n",
    "print(\"The categories in 'Partner' variables;.......\", end=\" \")\n",
    "print(df['Partner'].unique())\n",
    "\n",
    "print(\"The categories in 'Dependents' variables;.......\", end=\" \")\n",
    "print(df['Dependents'].unique())\n",
    "\n",
    "print(\"The categories in 'PhoneService' variables;.......\", end=\" \")\n",
    "print(df['PhoneService'].unique())\n",
    "\n",
    "print(\"The categories in 'MultipleLines' variables;.......\", end=\" \")\n",
    "print(df['MultipleLines'].unique())\n",
    "\n",
    "print(\"The categories in 'InternetService' variables;.......\", end=\" \")\n",
    "print(df['InternetService'].unique())\n",
    "\n",
    "print(\"The categories in 'OnlineSecurity' variables;.......\", end=\" \")\n",
    "print(df['OnlineSecurity'].unique())\n",
    "\n",
    "print(\"The categories in 'OnlineBackup' variables;.......\", end=\" \")\n",
    "print(df['OnlineBackup'].unique())\n",
    "\n",
    "print(\"The categories in 'DeviceProtection' variables;.......\", end=\" \")\n",
    "print(df['DeviceProtection'].unique())\n",
    "\n",
    "print(\"The categories in 'TechSupport' variables;.......\", end=\" \")\n",
    "print(df['TechSupport'].unique())\n",
    "\n",
    "print(\"The categories in 'StreamingTV' variables;.......\", end=\" \")\n",
    "print(df['StreamingTV'].unique())\n",
    "\n",
    "print(\"The categories in 'StreamingMovies' variables;.......\", end=\" \")\n",
    "print(df['StreamingMovies'].unique())\n",
    "\n",
    "print(\"The categories in 'Contract' variables;.......\", end=\" \")\n",
    "print(df['Contract'].unique())\n",
    "\n",
    "print(\"The categories in 'PaperlessBilling' variables;.......\", end=\" \")\n",
    "print(df['PaperlessBilling'].unique())\n",
    "\n",
    "print(\"The categories in 'PaymentMethod' variables;.......\", end=\" \")\n",
    "print(df['PaymentMethod'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f812d7d2-bbd5-441b-91b6-15ab25b4438b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['Churn']\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f3be9c-e454-46fa-a730-b95fe811c7ea",
   "metadata": {},
   "source": [
    "### Creating Column Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0233a4ec-b63b-4e96-8d41-f5b83d845521",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating column transformer\n",
    "num_features = x.select_dtypes(exclude=\"object\").columns\n",
    "cat_features = x.select_dtypes(include=\"object\").columns\n",
    "\n",
    "numerical_transformer = StandardScaler()\n",
    "categorical_transforemer = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    [\n",
    "      (\"OneHotEncoder\", categorical_transforemer, cat_features),\n",
    "      (\"StandardScaler\", numerical_transformer, num_features)  \n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd775ed-44bc-48d3-95fb-81891ff0a434",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "x_train.shape, x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dea6899-542a-4d81-acdb-5f7178a6a407",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor.fit(x_train)\n",
    "x_train_processed = preprocessor.transform(x_train)\n",
    "x_test_processed = preprocessor.transform(x_test)\n",
    "le = LabelEncoder()\n",
    "y_train_encoded = le.fit_transform(y_train)\n",
    "y_test_encoded = le.transform(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca191a0f-44e3-4de7-aa85-03e75039535e",
   "metadata": {},
   "source": [
    "### HyperParameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f6dfe4-363f-4658-aad8-7f5052546160",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "print(os.getcwd())\n",
    "CATBOOST_LOG_DIR = \"C:\\\\CatBoost_Temp\"\n",
    "if not os.path.exists(CATBOOST_LOG_DIR):\n",
    "    os.makedirs(CATBOOST_LOG_DIR)\n",
    "    print(f\"Created CatBoost log directory: {CATBOOST_LOG_DIR}\")\n",
    "else:\n",
    "    print(f\"CatBoost log directory already exists: {CATBOOST_LOG_DIR}\")\n",
    "\n",
    "\n",
    "params ={\n",
    "    \"logistic_regression\": {\n",
    "    'penalty': ['l1', 'l2', 'elasticnet', 'none'],\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "    'solver': ['saga'], # 'saga' supports 'l1', 'l2', 'elasticnet', 'none'\n",
    "    'max_iter': [1000]\n",
    "},\n",
    "    \n",
    "\"kneighbors_classifier\": {\n",
    "    'n_neighbors': [3, 5, 7, 9, 11, 15],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'metric': ['euclidean', 'manhattan']\n",
    "},\n",
    "\n",
    "\"decision_tree_classifier\": {\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': [None, 5, 10, 15, 20],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['sqrt', 'log2', None]\n",
    "},\n",
    "\n",
    "\"random_forest_classifier\": {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['sqrt', 'log2'],\n",
    "    'bootstrap': [True, False]\n",
    "},\n",
    "\n",
    "\"ada_boost_classifier\": {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'learning_rate': [0.01, 0.1, 0.5, 1.0],\n",
    "    'base_estimator': [DecisionTreeClassifier(max_depth=1), DecisionTreeClassifier(max_depth=2)] # Use shallow trees\n",
    "},\n",
    "\n",
    "\"gradient_boosting_classifier\": {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "    'max_depth': [3, 5, 7, 9],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'subsample': [0.7, 0.8, 0.9, 1.0]\n",
    "},\n",
    "\n",
    "\"svc\": {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "    'gamma': ['scale', 'auto', 0.1, 1]\n",
    "    # 'degree': [2, 3, 4] # Only relevant if kernel='poly'\n",
    "},\n",
    "\n",
    "\"catboost_classifier\": {\n",
    "    'loss_function': ['Logloss'], # Use ['Logloss'] for binary classification\n",
    "    # 'loss_function': ['MultiClass'], # Use ['MultiClass'] for multi-class classification\n",
    "    'iterations': [100, 200, 300, 500],\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "    'depth': [4, 6, 8, 10],\n",
    "    'l2_leaf_reg': [1, 3, 5, 7]\n",
    "    # 'random_seed': [42]\n",
    "},\n",
    "\n",
    "\"xgboost_classifier_params\": {\n",
    "    'objective': ['binary:logistic'], # Use ['binary:logistic'] for binary classification\n",
    "    # 'objective': ['multi:softmax'], # Use ['multi:softmax'] for multi-class classification\n",
    "    'n_estimators': [100, 200, 300, 500],\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "    'max_depth': [3, 5, 7, 9],\n",
    "    'subsample': [0.7, 0.8, 0.9, 1.0],\n",
    "    'colsample_bytree': [0.7, 0.8, 0.9, 1.0],\n",
    "    'gamma': [0, 0.1, 0.2, 0.3],\n",
    "    'reg_alpha': [0, 0.005, 0.01, 0.1],\n",
    "    'reg_lambda': [0, 0.005, 0.01, 0.1]\n",
    "},\n",
    "}\n",
    "\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(random_state=42),\n",
    "    \"K-Neighbors Classifier\": KNeighborsClassifier(),\n",
    "    \"Decision Tree Classifier\": DecisionTreeClassifier(random_state=42),\n",
    "    \"Random Forest Classifier\": RandomForestClassifier(random_state=42),\n",
    "    \"AdaBoost Classifier\": AdaBoostClassifier(random_state=42),\n",
    "    \"Gradient Boosting Classifier\": GradientBoostingClassifier(random_state=42),\n",
    "    \"Support Vector Classifier\": SVC(random_state=42), \n",
    "    \"CatBoost Classifier\": CatBoostClassifier(random_state=42, train_dir=CATBOOST_LOG_DIR),\n",
    "    \"XGB Classifier\": XGBClassifier(random_state=42)\n",
    "}\n",
    "\n",
    "model_report = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da72922e-64bd-4309-8129-159617bfa298",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASSIFICATION_SCORING_METRIC = 'accuracy'\n",
    "best_estimators_per_model = {}\n",
    "for name, model in models.items():\n",
    "    print(f\"--- Tuning hyperparameters for {name} ---\")\n",
    "\n",
    "    param_grid_for_model = params.get(name, {})\n",
    "\n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=model,\n",
    "        param_grid=param_grid_for_model,\n",
    "        cv=3,\n",
    "        scoring=CLASSIFICATION_SCORING_METRIC,\n",
    "        n_jobs=-1,\n",
    "        verbose=1,\n",
    "        error_score='raise'\n",
    "    )\n",
    "\n",
    "    grid_search.fit(x_train_processed, y_train_encoded)\n",
    "\n",
    "    best_model_for_fold = grid_search.best_estimator_\n",
    "    best_estimators_per_model[name] = best_model_for_fold # Store the best estimator\n",
    "\n",
    "    y_pred = best_model_for_fold.predict(x_test_processed)\n",
    "\n",
    "    if CLASSIFICATION_SCORING_METRIC == 'accuracy':\n",
    "        score = accuracy_score(y_test_encoded, y_pred)\n",
    "    elif CLASSIFICATION_SCORING_METRIC == 'f1_weighted':\n",
    "        score = f1_score(y_test_encoded, y_pred, average='weighted')\n",
    "    elif CLASSIFICATION_SCORING_METRIC == 'roc_auc':\n",
    "        score = roc_auc_score(y_test_encoded, y_pred)\n",
    "    else:\n",
    "        score = accuracy_score(y_test_encoded, y_pred)\n",
    "\n",
    "    model_report[name] = score\n",
    "    print(f\"{name} best {CLASSIFICATION_SCORING_METRIC} on test set: {score:.4f}\")\n",
    "\n",
    "best_model_score = max(model_report.values())\n",
    "best_model_name = [name for name, score in model_report.items() if score == best_model_score][0]\n",
    "\n",
    "print(f\"\\nBest Model: {best_model_name}, {CLASSIFICATION_SCORING_METRIC}: {best_model_score:.4f}\")\n",
    "\n",
    "if best_model_score < 0.6:\n",
    "    logging.warning(f\"No significantly good model found. Best {CLASSIFICATION_SCORING_METRIC} is {best_model_score:.4f}.\")\n",
    "else:\n",
    "    print(f\"\\nFinal evaluation of the overall best model ({best_model_name})...\")\n",
    "    final_best_model = best_estimators_per_model[best_model_name]\n",
    "\n",
    "    predicted = final_best_model.predict(x_test_processed)\n",
    "\n",
    "    if CLASSIFICATION_SCORING_METRIC == 'accuracy':\n",
    "        final_score = accuracy_score(y_test_encoded, predicted)\n",
    "    elif CLASSIFICATION_SCORING_METRIC == 'f1_weighted':\n",
    "        final_score = f1_score(y_test_encoded, predicted, average='weighted')\n",
    "    elif CLASSIFICATION_SCORING_METRIC == 'roc_auc':\n",
    "        final_score = roc_auc_score(y_test_encoded, predicted)\n",
    "    else:\n",
    "        final_score = accuracy_score(y_test_encoded, predicted)\n",
    "\n",
    "    print(f\"\\nFinal {CLASSIFICATION_SCORING_METRIC} of the best model ({best_model_name}) on the test set: {final_score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e657cfa1-6ded-4d17-8ebf-e6cfd05a16b1",
   "metadata": {},
   "source": [
    "### Difference between Actual and Predicted values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab483568-1992-483e-80af-32b269e83689",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df=pd.DataFrame({'Actual Value':y_test_encoded,'Predicted Value':y_pred,'Difference':y_test_encoded-y_pred})\n",
    "pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d078d32d-a223-4a40-88b2-3018fb939b72",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
